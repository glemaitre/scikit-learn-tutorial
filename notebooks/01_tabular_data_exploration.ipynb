{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will look at necessary steps that happen\n",
    "before any machine learning takes place:\n",
    "* load the data;\n",
    "* look at the variables in the dataset, in particular make the\n",
    "  difference between numerical and categorical variables, which\n",
    "  need different preprocessing in most machine learning workflows;\n",
    "* visualize the distribution of the variables to gain some\n",
    "  insights into the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inline plots\n",
    "%matplotlib inline\n",
    "\n",
    "# plotting style\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the adult census dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use data from the \"Current Population adult_census\" from\n",
    "1994 that we downloaded from [OpenML](http://openml.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "adult_census = pd.read_csv(\n",
    "    \"https://www.openml.org/data/get_csv/1595261/adult-census.csv\")\n",
    "\n",
    "# Or use the local copy: adult_census =\n",
    "# pd.read_csv('../datasets/adult- census.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the OpenML webpage to know more about this\n",
    "dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame('https://www.openml.org/d/1590', width=1200, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the variables in the dataset\n",
    "The data are stored in a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_census.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column named **class** is our target variable (i.e., the\n",
    "variable which we want to predict). The two possible classes are\n",
    "`<= 50K` (low-revenue) and `> 50K` (high-revenue)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'class'\n",
    "adult_census[target_column].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: classes are slightly imbalanced. Class imbalance happens\n",
    "often in practice and may need special techniques for machine\n",
    "learning. For example in a medical setting, if we are trying to\n",
    "predict whether patients will develop a rare disease, there will be\n",
    "a lot more sane patients than ill patients in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains both numerical and categorical data.\n",
    "Numerical values can take continuous values for example `age`.\n",
    "Categorical values can have a finite number of values, for example\n",
    "`native-country`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = [\n",
    "    'age', 'education-num', 'capital-gain', 'capital-loss',\n",
    "    'hours-per-week']\n",
    "categorical_columns = [\n",
    "    'workclass', 'education', 'marital-status', 'occupation',\n",
    "    'relationship', 'race', 'sex', 'native-country']\n",
    "all_columns = numerical_columns + categorical_columns + [\n",
    "    target_column]\n",
    "\n",
    "adult_census = adult_census[all_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for simplicity, we have ignored the \"fnlwgt\" (final\n",
    "weight) column that was crafted by the creators of the dataset when\n",
    "sampling the dataset to be representative of the full census\n",
    "database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the data\n",
    "Before building a machine learning model, it is a good idea to\n",
    "look at the data:\n",
    "* maybe the task you are trying to achieve can be solved\n",
    "  without machine learning\n",
    "* you need to check that the data you need for your task is\n",
    "  indeed present in the dataset\n",
    "* inspecting the data is a good way to find peculiarities.\n",
    "  These can can arise in the data collection (for example,\n",
    "  malfunctioning sensor or missing values), or the way the data is\n",
    "  processed afterwards (for example capped values)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the distribution of individual variables, to get\n",
    "some insights about the data. We can start by plotting histograms,\n",
    "note that this only works for numerical variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = adult_census.hist(figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can already make a few comments about some of the variables:\n",
    "* age: there are not that many points for 'age > 70'. The\n",
    "  dataset description does indicate that retired people have been\n",
    "  filtered out (`hours-per-week > 0`).\n",
    "* education-num: peak at 10 and 13, hard to tell what it\n",
    "  corresponds to without looking much further. We'll do that later\n",
    "  in this notebook.\n",
    "* hours per week at 40, this was very likely the standard of\n",
    "  working hours at the time of the data collection\n",
    "* most values of capital-gain and capital-loss are close to\n",
    "  zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "For categorical variables, we can look at the distribution of\n",
    "values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_census['sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_census['education'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas_profiling` is a nice tool for inspecting the data (both\n",
    "numerical and categorical variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling\n",
    "adult_census.profile_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "As noted above, `education-num` distribution has two clear peaks\n",
    "around 10 and 13. It would be reasonable to expect that 'education-\n",
    "num' is the number of years of education. Let's look at the\n",
    "relationship between education and education-num."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=adult_census['education'],\n",
    "            columns=adult_census['education-num'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that education and education-num are redundant. For\n",
    "example, `education-num=2` is equivalent to `education='1st-4th'`.\n",
    "In practice that means we can remove `education-num` without losing\n",
    "information. Note that having redundant (or highly correlated)\n",
    "columns can be a problem for machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to inspect the data is to do a pairplot and show how\n",
    "variable differ according to the class. In the diagonal you can see\n",
    "the distribution of individual variables. The plots on the off-\n",
    "diagonal can reveal interesting interactions between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_to_plot = 5000\n",
    "columns = ['age', 'education-num', 'hours-per-week']\n",
    "_ = sns.pairplot(data=adult_census[:n_samples_to_plot], vars=columns,\n",
    "                 hue=target_column, plot_kws={'alpha': 0.2},\n",
    "                 height=4, diag_kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.pairplot(data=adult_census[:n_samples_to_plot], x_vars='age',\n",
    "                 y_vars='hours-per-week', hue=target_column,\n",
    "                 markers=['o',\n",
    "                          'v'], plot_kws={'alpha': 0.2}, height=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "\n",
    "By looking at the data you could infer some hand-written rules to\n",
    "predict the class:\n",
    "* if you are young (less than 25 year-old roughly), you are in\n",
    "  the `<= 50K` class.\n",
    "* if you are old (more than 70 year-old roughly), you are in\n",
    "  the `<= 50K` class.\n",
    "* if you work part-time (less than 40 hours roughly) you are in\n",
    "  the `<= 50K` class.\n",
    "\n",
    "These hand-written rules could work reasonably well without the\n",
    "need for any machine learning. Note however that it is not very\n",
    "easy to create rules for the region `40 < hours-per-week < 60` and\n",
    "`30 < age < 70`. We can hope that machine learning can help in this\n",
    "region. Also note that visualization can help creating hand-written\n",
    "rules but is limited to 2 dimensions (maybe 3 dimensions), whereas\n",
    "machine learning models can build models in high- dimensional\n",
    "spaces.\n",
    "\n",
    "Another thing worth mentioning in this plot: if you are young\n",
    "(less than 25 year-old roughly) you tend to work less and if you\n",
    "are old (more than 70 year-old roughly). This is a non-linear\n",
    "relationship between age and hours per week. Some machine learning\n",
    "models can only capture linear interaction so this may be a factor\n",
    "when deciding which model to chose.\n",
    "\n",
    "In a machine-learning setting, we will use an algorithm to\n",
    "automatically decide what should be the \"rules\" in order to predict\n",
    "on new data. We can check which set of simple rule a decision tree\n",
    "would grasp using the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tree_decision_function(tree, X, y, ax):\n",
    "    \"\"\"Plot the different decision rules found by a `DecisionTreeClassifier`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tree : DecisionTreeClassifier instance\n",
    "        The decision tree to inspect.\n",
    "    X : dataframe of shape (n_samples, n_features)\n",
    "        The data used to train the `tree` estimator.\n",
    "    y : ndarray of shape (n_samples,)\n",
    "        The target used to train the `tree` estimator.\n",
    "    ax : matplotlib axis\n",
    "        The matplotlib axis where to plot the different decision rules.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from scipy import ndimage\n",
    "\n",
    "    h = 0.02\n",
    "    x_min, x_max = 0, 100\n",
    "    y_min, y_max = 0, 100\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "\n",
    "    Z = tree.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    faces = tree.tree_.apply(\n",
    "        np.c_[xx.ravel(), yy.ravel()].astype(np.float32))\n",
    "    faces = faces.reshape(xx.shape)\n",
    "    border = ndimage.laplace(faces) != 0\n",
    "    ax.scatter(X.iloc[:, 0], X.iloc[:, 1],\n",
    "               c=np.array(['tab:blue',\n",
    "                           'tab:red'])[y], s=60, alpha=0.7)\n",
    "    ax.contourf(xx, yy, Z, alpha=.4, cmap='RdBu_r')\n",
    "    ax.scatter(xx[border], yy[border], marker='.', s=1)\n",
    "    ax.set_xlabel(X.columns[0])\n",
    "    ax.set_ylabel(X.columns[1])\n",
    "    ax.set_xlim([x_min, x_max])\n",
    "    ax.set_ylim([y_min, y_max])\n",
    "    sns.despine(offset=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)  # reset the plotting style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# select a subset of data\n",
    "data_subset = adult_census[:n_samples_to_plot]\n",
    "X = data_subset[[\"age\", \"hours-per-week\"]]\n",
    "y = LabelEncoder().fit_transform(\n",
    "    data_subset[target_column].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a decision tree which we will keep really simple\n",
    "on purpose. We will only allow a maximum of 2 rules to interpret\n",
    "the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "max_leaf_nodes = 3\n",
    "tree = DecisionTreeClassifier(max_leaf_nodes=max_leaf_nodes,\n",
    "                              random_state=0)\n",
    "tree.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now first check the set of rules learnt by the tree and\n",
    "check visually what theses rules look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the tree structure\n",
    "fig, ax = plt.subplots()\n",
    "plot_tree(tree, ax=ax)\n",
    "\n",
    "# plot the decision function learned by the tree\n",
    "fig, ax = plt.subplots()\n",
    "plot_tree_decision_function(tree, X, y, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allowing only 3 leaves in the tree, we get similar rules than the\n",
    "one designed by hand:\n",
    "* the persons younger than 28.5 year-old will be considered in\n",
    "  the class earning `<= 50K`.\n",
    "* the persons older than 28.5 and working more than 40.5 hours-\n",
    "  per-week will be considered in the class earning `> 50K`, while\n",
    "  the one working below 40.5 hours-per-week, will be considered in\n",
    "  the class earning `<= 50K`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "\n",
    "In this notebook we have:\n",
    "* loaded the data from a CSV file using `pandas`\n",
    "* looked at the kind of variables in the dataset, and make the\n",
    "  difference between categorical and numerical variables.\n",
    "* inspected the data with `pandas`, `seaborn` and\n",
    "  `pandas_profiling`. Data inspection can allow you to decide\n",
    "  whether using machine learning is appropriate for your data and\n",
    "  to notice potential peculiarities in your data."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "python_scripts//py:percent,notebooks//ipynb",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
